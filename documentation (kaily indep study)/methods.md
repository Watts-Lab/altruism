In our experiment, we aimed to investigate pro-social behavior among workers on Amazon’s Mechanical Turk platform within a controlled yet ecologically valid setting. Specifically, we sought to understand the decision-making processes and overall pro-social tendencies of workers when engaging with a pool of HITs that appeared to be sourced from one another.

Participants were recruited for our experiment in two ways. The first group of workers, who we referred to as the “sharers”, were invited to join our experiment and complete a set of HITs comprising of various surveys and common crowd-sourcing tasks. After accepting this work, the sharers were given a share code which they could use to invite other workers into the study. The workers who joined the experiment through this method were referred to as the “receivers”.

Our experimental design incorporated key elements to maintain the validity of our system, while also allowing us to observe and analyze participant interactions, decision-making processes, and task completion dynamics within a controlled experimental framework. Firstly, we parameterized conditions to explore the impact of sharing. An advantage of the design of our system within Mechanical Turk is that costs associated with completing each HIT can be manipulated. That is, we can explicitly alter both the monetary reward for each completed HIT and the level of difficulty associated with each task. This involves dynamically selecting tasks that may require more or less time to complete, or tasks that vary in complexity, allowing for a flexible adjustment of the experimental conditions. This maleability in task design allowed us to capture more nuanced insights int the decision-making processes of participants when deciding whether or not to share work with other Mechanical Turk workers.

Moreover, we implemented a dynamic system to randomly assign sharers into two experimental conditions — costless or costful — after they opted into the experiment. In the costless treatment, participants could invite workers into the experiment without impacting their own work. The receivers that were invited into the experiment in this condition were also presented with a set of HITs that were independent of any other workers on the platform. In the second treatment, receivers who opted into the experiment were also given a set of HITs to complete. However, these receivers were also placed into a network that included the sharer and all other workers who had joined the experiment via the sharer’s code. Each HIT completed by a worker in this network dynamically responded to the quantity of HITs for the remaining participants in the network. Specifically, each HIT completed in this network resulted in a decrement of one from each of the other players’ total remaining HITs.

Crucially, this system allows us to control how many HITs every participant can complete while maintaining ecological validity. From the participant’s perspective, all work is done on the established Mechanical Turk platform, and HITs are generated and expired in their standard process. However, we maintain control over how many HITs each participant can complete, and can intervene on the HIT creation and expiration process. This proactive approach is critical, as the worker community may express concerns about this form of intervention. While our design is transparent about the experiment's dynamics, we have the flexibility to generate additional tasks if needed.
